Dear {{ center_name }} user,

Your allocation request for {{ resource }} has been activated and it may take up to 2 hours for these changes to propagate through the system.

To view your allocations information, please go to {{ allocation_url }}

The Quartz system consists of 92 nodes, each with two AMD EPYC 7742 2.25 GHz CPUs and 512 GB of RAM.
The system also consists of 24 GPU-accelerated Apollo 6500 nodes equipped with two Intel 6248 2.5 GHz 20-core CPUs, four NVIDIA Tesla V100 PCIe 32 GB GPUs, one 1.92 TB solid-state drive, and 768 GB of RAM.

The system is managed via the Slurm scheduler. You can log into a Big Red 200 login node and submit jobs to one of the available partitions. The fiev partitions are general, debug, interactive, gpu, and gpu-debug.
You will need to specify the required GPU resource for each job using the gpus tag. For example to request 2 GPUs per requested node: #SBATCH --gpus-per-node=v100:2

For more information about Quartz you can refer to the Knowledge Base article https://servicenow.iu.edu/kb?id=kb_article_view&sysparm_article=KB0023985.
For more information on the GPU nodes themselves you can refer to the Knowledge Base article https://servicenow.iu.edu/kb?id=kb_article_view&sysparm_article=KB0022436.

Another article https://servicenow.iu.edu/kb?id=kb_article_view&sysparm_article=KB0023298, contains more information on the Slurm scheduler. If you need help using the Slurm scheduler please donâ€™t hesitate to contact us at {{ help_url }}.

To use this new account you will need to add this line to your job script:
#SBATCH -A {{ slurm_account_name }}

Interactive jobs will require this:
srun -A {{ slurm_account_name }} <commands>

We are also happy to help with the development and optimization of your workflow, just contact us at {{ help_url }}. Thanks!

Thank you,
{{ signature }}
